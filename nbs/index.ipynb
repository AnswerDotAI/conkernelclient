{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "585fc44a",
   "metadata": {},
   "source": [
    "# conkernelclient\n",
    "\n",
    "> Concurrent-safe Jupyter KernelClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffe6734",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966efee7",
   "metadata": {},
   "source": [
    "Jupyter's `KernelClient` is designed around a simple request-reply pattern: you send one message on the shell channel, wait for its reply, then send the next. This works fine for a single-threaded notebook, but falls apart when you need concurrent execution. For instance, running multiple cells in parallel, or letting an LLM tool loop fire off code while a long-running computation is still in flight. The underlying ZMQ socket isn't safe to share across tasks, and there's no built-in mechanism to route replies back to the correct caller when multiple requests are outstanding.\n",
    "\n",
    "*conkernelclient* solves this with `ConKernelClient`, a drop-in replacement for `AsyncKernelClient` that makes concurrent `execute()` calls safe. It patches `Session.send` to synchronise with the ZMQ I/O thread (preventing a race where two sends interleave), and spins up a dedicated reader task on the shell channel that demultiplexes incoming replies by message ID. Each `execute(..., reply=True)` call gets its own `asyncio.Queue`, so multiple coroutines can `await` their replies independently without interfering with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9f8823",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f52505",
   "metadata": {},
   "source": [
    "Install from [pypi][pypi]\n",
    "\n",
    "\n",
    "```sh\n",
    "$ pip install conkernelclient\n",
    "```\n",
    "\n",
    "[pypi]: https://pypi.org/project/conkernelclient/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ecfcc7",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83848e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conkernelclient import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dc140e",
   "metadata": {},
   "source": [
    "The main entry point is `ConKernelManager`, a drop-in replacement for `AsyncKernelManager` that creates `ConKernelClient` instances. Start a kernel and connect a client in the usual way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6f9be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from jupyter_client.session import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32fc6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km = ConKernelManager(session=Session(key=b'x'))\n",
    "await km.start_kernel()\n",
    "kc = await km.client().start_channels()\n",
    "await kc.is_alive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f351010",
   "metadata": {},
   "source": [
    "Once connected, `execute()` works like the standard client. Pass `reply=True` to await the shell reply, or `reply=False` (the default) to fire-and-forget and collect results later via `get_pubs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdd790e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ok'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = await kc.execute('2+1', timeout=1, reply=True)\n",
    "r['content']['status']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398c249c",
   "metadata": {},
   "source": [
    "The key feature is safe concurrent execution. Multiple `execute(..., reply=True)` calls can be outstanding simultaneously â€” each gets its own `asyncio.Queue`, and a background reader task routes replies by message ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795c455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23d4447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dab23f68-96c28dd9c776844176afdff1_66028_2'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = kc.execute('x=2', reply=True)\n",
    "b = kc.execute('y=3', reply=True)\n",
    "r = await asyncio.wait_for(asyncio.gather(a, b), timeout=2)\n",
    "test_eq(len(r), 2)\n",
    "r[0]['parent_header']['msg_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ec3c69",
   "metadata": {},
   "source": [
    "Both replies arrive independently, each routed to the correct caller. Without `ConKernelClient`, the second `execute` would either block waiting for the first to finish, or the replies would get crossed.\n",
    "\n",
    "As usual, we clean up when we're done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859cf6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if await km.is_alive():\n",
    "    kc.stop_channels()\n",
    "    await km.shutdown_kernel()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
